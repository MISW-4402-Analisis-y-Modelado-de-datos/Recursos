{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tutorial: creación de ETLs con PySpark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introducción\t\n",
    "    ¿Qué aprenderá?\n",
    "\tEn este tutorial aprenderá cómo puede utilizar PySpark para crear un proceso de ETL básico.\n",
    "\n",
    "\t¿Qué construirá?     \n",
    "        Construirá un ETL que toma los datos desde la base de datos transacional de WideWorldImporters (WWImportersTransactional), los transforma  a una representación cercana al análisis y los  almacena en la base de datos relacional WWImportersDWH.\n",
    "    \n",
    "\t¿Para qué?\n",
    "\tLa construcción de ETLs que se ajusten a modelos multidimensionales es un paso necesario dentro de un proceso de analìtica 1.0 , pues permite tomar los datos crudos de una fuente, generalmente transaccional, para transformarlos en datos limpios que puedan utilizarse para la toma de decisiones.\n",
    "    \n",
    "    ¿Qué necesita?\n",
    "    1. Python 3 con pip instalado\n",
    "    2. Jupyter notebook\n",
    "    3. Paquetes: Pyspark (3.0.1) y pandas (1.2.1)\n",
    "    4. Controlador Connector J de MySQL (ya se encuentra instalado)\n",
    "    5. Servidor SQL con base de datos relacional \"WWImportersTransactional\" y base de datos relacional que corresponde a la bodega de WWI \"Estudiante_i\"\n",
    "\t"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Proceso de ETL para una dimensión."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este proceso de ETL, se extraen los datos de las **órdenes de compra** de una base de datos transaccional y se almacenan en otra base de datos que corresponde a la bodega de datos, siguiendo una aproximación ROLAP. A continuación, se presenta el modelo multidimensional que es el modelo conceptual que representa el proceso de registro de órdenes de compra. Este modelo se utilizó para crear las tablas en la bodega de datos que representan el proceso de negocio y que serán cargadas como resultado del proceso ETL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Modelo ordenes](./WWI_modelo_ordenes.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El proceso de ETL debe ser diseñado antes de implementarse. A partir de las conclusiones del entendimiento de datos sabemos las fuentes que se van a  utilizar y la relación entre las fuentes. Adicionalmente, se cuenta con las respuestas de la organización a las preguntas, resultado del entendimiento de datos. De esa manera sabemos cómo se deben manipular los datos. \n",
    "\n",
    "Este proceso de ETL lo dividimos en seis bloques, uno para cada dimensión o <i>tabla de hechos</i> del modelo, con la única excepción de la dimensión de fecha que, por ser una dimensión especial que se genera de forma independiente, no se incluye aquí:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![ETL](./Disenio_ETL.PNG)\n",
    "\n",
    "Recuerde que este es el diseño general. En el diseño completo se deben incluir las transformaciones realizadas a los datos a utilizarse en las dimensiones y tablas de hecho del modelo multidimensional, de acuerdo a lo que se muestra en la infografía de arquitectura de componentes (Componente proceso ETL) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuración servidor base de datos transaccional\n",
    "# Recuerde usar Estudiante_i como usuario y la contraseña asigana en el excel de conexión a maquina virtual como contraseña\n",
    "db_user = ''\n",
    "db_psswd = ''\n",
    "source_db_connection_string = 'jdbc:mysql://157.253.236.116:8080/WWImportersTransactional'\n",
    "\n",
    "dest_db_connection_string = 'jdbc:mysql://157.253.236.116:8080/Estudiante_43'\n",
    "\n",
    "# Driver de conexion\n",
    "path_jar_driver = 'C:\\Program Files (x86)\\MySQL\\Connector J 8.0\\mysql-connector-java-8.0.28.jar'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from pyspark.sql import functions as f, SparkSession, types as t\n",
    "from pyspark import SparkContext, SparkConf, SQLContext\n",
    "from pyspark.sql.functions import udf, col, length, isnan, when, count, regexp_replace\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\leidy\\Downloads\\MISO\\ambiente\\lib\\site-packages\\pyspark\\sql\\context.py:77: FutureWarning: Deprecated in 3.0.0. Use SparkSession.builder.getOrCreate() instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Configuración de la sesión\n",
    "conf=SparkConf() \\\n",
    "    .set('spark.driver.extraClassPath', path_jar_driver)\n",
    "\n",
    "spark_context = SparkContext(conf=conf)\n",
    "sql_context = SQLContext(spark_context)\n",
    "spark = sql_context.sparkSession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conexión y carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se define la función para conexión y cargue de dataframes desde la base de datos origen y luego la función para guardar un dataframe en una tabla de la base de datos destino."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obterner_dataframe_desde_csv(_PATH, _sep):\n",
    "    return spark.read.load(_PATH, format=\"csv\", sep=_sep, inferSchema=\"true\", header='true')\n",
    "\n",
    "def obtener_dataframe_de_bd(db_connection_string, sql, db_user, db_psswd):\n",
    "    df_bd = spark.read.format('jdbc')\\\n",
    "        .option('url', db_connection_string) \\\n",
    "        .option('dbtable', sql) \\\n",
    "        .option('user', db_user) \\\n",
    "        .option('password', db_psswd) \\\n",
    "        .option('driver', 'com.mysql.cj.jdbc.Driver') \\\n",
    "        .load()\n",
    "    return df_bd\n",
    "\n",
    "def guardar_db(db_connection_string, df, tabla, db_user, db_psswd):\n",
    "    df.select('*').write.format('jdbc') \\\n",
    "      .mode('append') \\\n",
    "      .option('url', db_connection_string) \\\n",
    "      .option('dbtable', tabla) \\\n",
    "      .option('user', db_user) \\\n",
    "      .option('password', db_psswd) \\\n",
    "      .option('driver', 'com.mysql.cj.jdbc.Driver') \\\n",
    "      .save()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOQUE 1\n",
    "Empezamos con el bloque 1: la dimensión <i>Empleado</i>, su fuente de datos viene de la tabla transaccional <i>Personas</i>. En la sentencia SQL filtramos usando WHERE para seleccionar solo las personas que sean vendedores y recuperamos únicamente los atributos que queremos, de acuerdo con  modelo dimensional. Recuerde que también puede usar el **.select()** de pyspark si no conoce los atributos de las tablas transaccionales. Sin embargo, es más eficiente aplicar el filtro en la consulta, ya que no trae a memoria más información de la necesaria."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracción\n",
    "A continuación, nos conectamos a la base de datos y extraemos la información deseada por medio de SQL, cargandola en un DataFrame PySpark, es decir en memoria. Note que aquí se pueden renombrar los atributos con la estructura <i>nombreActual AS nuevoNombre</i>. De la tabla de personas, En este paso, solo nos interesan los empleados, por lo cual se hace un filtro por medio del WHERE, buscando las personas cuyo atributo EsVendedor sea igual a 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------+--------------+----------+\n",
      "|ID_Empleado|        Nombre|EsVendedor|\n",
      "+-----------+--------------+----------+\n",
      "|          2|Kayla Woodcock|      true|\n",
      "|          3| Hudson Onslow|      true|\n",
      "|          6| Sophia Hinton|      true|\n",
      "|          7|     Amy Trefl|      true|\n",
      "|          8|Anthony Grosse|      true|\n",
      "+-----------+--------------+----------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sql_empleados = '''(SELECT ID_persona AS ID_Empleado, NombreCompleto AS Nombre, EsVendedor FROM WWImportersTransactional.Personas WHERE EsVendedor=1) AS Temp_empleados'''\n",
    "empleados = obtener_dataframe_de_bd(source_db_connection_string, sql_empleados, db_user, db_psswd)\n",
    "empleados.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformación\n",
    "Recuerde que, puede hacer uso de selectExpr, filter, where entre otras de PySpark para modificar los datos cargados. Por ejemplo, el siguiente código utiliza <i>selectExpr</i> para renombrar la columna ID_Empleado por ID_Empleado_T, esta es la convención que vamos a utilizar: \"_T\" para indicar que el ID es el que estaba en la base de datos transaccional y \"_DWH\" para indicar que son ID's propios de la bodega. Usamos withColumn y monotonicallu_increasing_id para crear un ID acumulativo para cada registro en el dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+--------------+---------------+\n",
      "|ID_Empleado_T|        Nombre|ID_Empleado_DWH|\n",
      "+-------------+--------------+---------------+\n",
      "|            2|Kayla Woodcock|              1|\n",
      "|            3| Hudson Onslow|              2|\n",
      "|            6| Sophia Hinton|              3|\n",
      "|            7|     Amy Trefl|              4|\n",
      "|            8|Anthony Grosse|              5|\n",
      "+-------------+--------------+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMACION\n",
    "empleados = empleados.selectExpr('ID_Empleado as ID_Empleado_T','Nombre')\n",
    "empleados = empleados.withColumn('ID_Empleado_DWH', f.monotonically_increasing_id() + 1)\n",
    "empleados.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga\n",
    "Una vez realizado esto, se guardan los resultados en la base de datos destino"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, empleados,'Estudiante_43.Empleado', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOQUE 2\n",
    "Empezamos el bloque 2: dimensión ciudad. Su fuente de datos es una combinación de las tablas transaccionales <i>paises, provinciasEstados y ciudades</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ID_ciudad_T', 'NombreCiudad', 'ID_EstadoProvincia', 'Poblacion'] ['ID_Pais', 'Nombre', 'Continente', 'Region', 'Subregion'] ['ID_EstadoProvincia', 'NombreEstadoProvincia', 'TerritorioVentas', 'ID_Pais']\n"
     ]
    }
   ],
   "source": [
    "#EXTRACCION\n",
    "sql_paises = '''(SELECT ID_Pais, Nombre, Continente, Region, Subregion FROM WWImportersTransactional.Paises) AS Temp_paises'''\n",
    "sql_provincias_estados = '''(SELECT ID_EstadosProvincias AS ID_EstadoProvincia, NombreEstadoProvincia, TerritorioVentas, ID_Pais FROM WWImportersTransactional.EstadosProvincias) AS Temp_estados_provincias'''\n",
    "sql_ciudades = '''(SELECT ID_ciudad as ID_ciudad_T, NombreCiudad, ID_EstadoProvincia, Poblacion FROM WWImportersTransactional.Ciudades) AS Temp_ciudades'''\n",
    "\n",
    "paises = obtener_dataframe_de_bd(source_db_connection_string, sql_paises, db_user, db_psswd)\n",
    "provincias_estados = obtener_dataframe_de_bd(source_db_connection_string, sql_provincias_estados, db_user, db_psswd)\n",
    "ciudades = obtener_dataframe_de_bd(source_db_connection_string, sql_ciudades, db_user, db_psswd)\n",
    "\n",
    "print(ciudades.columns, paises.columns, provincias_estados.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+-----------+------------+---------+---------------------+----------------+-------------+-------------+--------+----------------+-------------+\n",
      "|ID_Pais|ID_EstadoProvincia|ID_ciudad_T|NombreCiudad|Poblacion|NombreEstadoProvincia|TerritorioVentas|       Nombre|   Continente|  Region|       Subregion|ID_Ciudad_DWH|\n",
      "+-------+------------------+-----------+------------+---------+---------------------+----------------+-------------+-------------+--------+----------------+-------------+\n",
      "|    230|                31|         49|     Absecon|     8411|           New Jersey|         Mideast|United States|North America|Americas|Northern America|            1|\n",
      "|    230|                31|        150|    Adelphia|     null|           New Jersey|         Mideast|United States|North America|Americas|Northern America|            2|\n",
      "|    230|                31|        336|      Albion|     null|           New Jersey|         Mideast|United States|North America|Americas|Northern America|            3|\n",
      "|    230|                31|        458|   Allamuchy|       78|           New Jersey|         Mideast|United States|North America|Americas|Northern America|            4|\n",
      "|    230|                31|        480|   Allendale|     6505|           New Jersey|         Mideast|United States|North America|Americas|Northern America|            5|\n",
      "+-------+------------------+-----------+------------+---------+---------------------+----------------+-------------+-------------+--------+----------------+-------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMACION\n",
    "ciudades = ciudades.join(provincias_estados, how = 'inner', on = 'ID_EstadoProvincia')\n",
    "ciudades = ciudades.join(paises, how = 'inner', on = 'ID_Pais')\n",
    "ciudades = ciudades.withColumn('ID_Ciudad_DWH', f.monotonically_increasing_id() + 1)\n",
    "ciudades.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, ciudades,'Estudiante_43.Ciudad', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOQUE 3\n",
    "Bloque 3: dimensión paquete. Su fuente de datos es la tabla transaccional <i>Paquetes</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXTRACCION\n",
    "sql_paquetes = '''(SELECT ID_TipoPaquete AS ID_TipoPaquete_T, TipoPaquete AS Nombre FROM WWImportersTransactional.Paquetes) AS Temp_Paquetes'''\n",
    "paquetes = obtener_dataframe_de_bd(source_db_connection_string, sql_paquetes, db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------+------------------+\n",
      "|ID_TipoPaquete_T|Nombre|ID_TipoPaquete_DWH|\n",
      "+----------------+------+------------------+\n",
      "|               1|   Bag|                 1|\n",
      "|               2| Block|                 2|\n",
      "|               3|Bottle|                 3|\n",
      "|               4|   Box|                 4|\n",
      "|               5|   Can|                 5|\n",
      "+----------------+------+------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMACION\n",
    "paquetes = paquetes.withColumn('ID_TipoPaquete_DWH', f.monotonically_increasing_id() + 1)\n",
    "paquetes.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, paquetes,'Estudiante_43.TipoPaquete', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOQUE 4\n",
    "Bloque 4: dimensión producto, su fuente de datos es la combinación entre las tablas transaccionales Productos y Colores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_productos = '''(SELECT ID_Producto as ID_Producto_T, ID_Color, NombreProducto, Marca, Necesita_refrigeracion, Dias_tiempo_entrega, Impuesto, PrecioUnitario, PrecioRecomendado FROM WWImportersTransactional.Producto) AS Temp_productos'''\n",
    "sql_colores = '''(SELECT ID_Color, Color FROM WWImportersTransactional.Colores) AS Temp_colores'''\n",
    "\n",
    "productos = obtener_dataframe_de_bd(source_db_connection_string, sql_productos, db_user, db_psswd)\n",
    "colores = obtener_dataframe_de_bd(source_db_connection_string, sql_colores, db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+-------------+--------------------+-----+----------------------+-------------------+--------+--------------+-----------------+-----+---------------+\n",
      "|ID_Color|ID_Producto_T|      NombreProducto|Marca|Necesita_refrigeracion|Dias_tiempo_entrega|Impuesto|PrecioUnitario|PrecioRecomendado|Color|ID_Producto_DWH|\n",
      "+--------+-------------+--------------------+-----+----------------------+-------------------+--------+--------------+-----------------+-----+---------------+\n",
      "|       3|            3|Office cube peris...| null|                     0|                 14|      15|            19|               28|Black|              1|\n",
      "|       3|           17|DBA joke mug - mi...| null|                     0|                 12|      15|            13|               19|Black|              2|\n",
      "|       3|           19|DBA joke mug - da...| null|                     0|                 12|      15|            13|               19|Black|              3|\n",
      "|       3|           21|DBA joke mug - yo...| null|                     0|                 12|      15|            13|               19|Black|              4|\n",
      "|       3|           23|DBA joke mug - it...| null|                     0|                 12|      15|            13|               19|Black|              5|\n",
      "+--------+-------------+--------------------+-----+----------------------+-------------------+--------+--------------+-----------------+-----+---------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMACION\n",
    "productos = productos.join(colores, how = 'inner', on = 'ID_Color')\n",
    "productos = productos.withColumn('ID_Producto_DWH', f.monotonically_increasing_id() + 1)\n",
    "productos.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string, productos,'Estudiante_43.Producto', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOQUE 5\n",
    "Bloque 5: dimensión cliente. Su fuente de datos es la combinación entre las tablas transaccionales Categorias de cliente, Grupos de compra y Clientes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_categoriasCliente = '''(SELECT ID_Categoria, NombreCategoria FROM WWImportersTransactional.CategoriasCliente) AS Temp_categoriasclientes'''\n",
    "sql_gruposCompra = '''(SELECT ID_GrupoCompra, NombreGrupoCompra FROM WWImportersTransactional.GruposCompra) AS Temp_gruposcompra'''\n",
    "sql_clientes = '''(SELECT ID_Cliente as ID_Cliente_T, Nombre, ClienteFactura, ID_Categoria, ID_GrupoCompra, ID_CiudadEntrega, LimiteCredito, FechaAperturaCuenta, DiasPago FROM WWImportersTransactional.Clientes) AS Temp_clientes'''\n",
    "\n",
    "categoriasCliente = obtener_dataframe_de_bd(source_db_connection_string, sql_categoriasCliente, db_user, db_psswd)\n",
    "gruposCompra = obtener_dataframe_de_bd(source_db_connection_string, sql_gruposCompra, db_user, db_psswd)\n",
    "clientes = obtener_dataframe_de_bd(source_db_connection_string, sql_clientes, db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+--------------+------------+--------------------+--------------+----------------+-------------+-------------------+--------+-----------------+---------------+--------------+\n",
      "|ID_Categoria|ID_GrupoCompra|ID_Cliente_T|              Nombre|ClienteFactura|ID_CiudadEntrega|LimiteCredito|FechaAperturaCuenta|DiasPago|NombreGrupoCompra|NombreCategoria|ID_Cliente_DWH|\n",
      "+------------+--------------+------------+--------------------+--------------+----------------+-------------+-------------------+--------+-----------------+---------------+--------------+\n",
      "|           3|             2|         601|Wingtip Toys (Rut...|           401|           29887|         null|2013-01-01 00:00:00|       7|     Wingtip Toys|   Novelty Shop|             1|\n",
      "|           3|             2|         600|Wingtip Toys (Car...|           401|            5407|         null|2013-01-01 00:00:00|       7|     Wingtip Toys|   Novelty Shop|             2|\n",
      "|           3|             2|         599|Wingtip Toys (Dic...|           401|            9077|         null|2013-01-01 00:00:00|       7|     Wingtip Toys|   Novelty Shop|             3|\n",
      "|           3|             2|         598|Wingtip Toys (Kap...|           401|           17340|         null|2013-01-01 00:00:00|       7|     Wingtip Toys|   Novelty Shop|             4|\n",
      "|           3|             2|         597|Wingtip Toys (Hay...|           401|           14965|         null|2013-01-01 00:00:00|       7|     Wingtip Toys|   Novelty Shop|             5|\n",
      "+------------+--------------+------------+--------------------+--------------+----------------+-------------+-------------------+--------+-----------------+---------------+--------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# TRANSFORMACION\n",
    "clientes = clientes.join(gruposCompra, how = 'inner', on = 'ID_GrupoCompra')\n",
    "clientes = clientes.join(categoriasCliente, how = 'inner', on = 'ID_Categoria')\n",
    "clientes = clientes.withColumn('ID_Cliente_DWH', f.monotonically_increasing_id() + 1)\n",
    "clientes.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CARGUE\n",
    "guardar_db(dest_db_connection_string,clientes,'Estudiante_43.Cliente', db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BLOQUE 6\n",
    "Bloque 6: Hecho orden. Su fuente de datos es la combinación entre las tablas transaccionales Ordenes y detalles de orden"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Extracción"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "sql_ordenes = '''(SELECT * FROM WWImportersTransactional.Ordenes) AS Temp_ordenes'''\n",
    "sql_detallesOrdenes = '''(SELECT * FROM WWImportersTransactional.DetallesOrdenes) AS Temp_detallesordenes'''\n",
    "ordenes = obtener_dataframe_de_bd(source_db_connection_string, sql_ordenes, db_user, db_psswd)\n",
    "detallesOrdenes = obtener_dataframe_de_bd(source_db_connection_string, sql_detallesOrdenes, db_user, db_psswd)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transformación\n",
    "Estas son las respuestas de Wide World Importers a los conclusiones obtenidas en el entendimiento de los datos:\n",
    "- La regla de negocio \"La tasa de impuesto es de 10% o 15%\" es correcta, pero habian errores en la tabla original, que fueron corregidos. \n",
    "- Para la segunda regla de negocio: \"Son 73.595 órdenes detalladas en 231.412 lineas de detalle de órdenes realizadas desde 2013\", si faltaban datos, los cuales fueron completados, y nos dicen que en cuanto a consistencia ellos revisaron las tablas e hicieron correcciones, pero que los duplicados completos de ordenes los eliminemos\n",
    "- \"El formato de fechas manejado es YYYY-MM-DD HH:MM:SS si tienen hora, minutos y segundos. De lo contrario el formato es YYYY-MM-DD\": En cuanto a formatos de fechas estan de acuerdo con que los estandarizemos y el formato sea el especificado en la regla\n",
    "- Para las descripciones de productos que eran \"a\", se actualizaron a los valores reales. \n",
    "- Se pueden eliminar las columnas Comenarios, Instrucciones_de_entrega y comentarios_internos porque estan vacias. \n",
    "- A pesar de estar en un proceso de mejorar la calidad de los datos y mantener los nulos nos ayudaría a reflejar esa calidad, de la mano con el grupo de analitica de WWI se decide imputar por la media el valor extremo de la variable Cantidad\n",
    "- Para las ordenes las columnas Seleccionado_por_ID_de_persona, ID_de_pedido_pendiente, Seleccion_completada_cuando, y para las columnas Seleccion_completada_cuando de la tabla detalles de ordenes, se decide mantener los valores vacíos, sin embargo para la variable Precio_unitario el negocio reviso y complemento los valores faltantes\n",
    "\n",
    "Las tablas usadas en el tutorial de entendimiento de datos estaran disponibles para su revision con los siguientes nombres: OrdenesCopia y DetallesOrdenesCopia. \n",
    "\n",
    "Para este tutorial vamos a trabajar con unas tablas que dadas las conclusiones del tutorial de entendimiento, WWImporters revisó los datos originales, creo tablas y las llamo \"Ordenes\" y \"DetallesOrdenes\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace una verificación de los valores de la tasa de impuesto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+\n",
      "|Tasa_de_impuesto|\n",
      "+----------------+\n",
      "|              10|\n",
      "|              15|\n",
      "+----------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "detallesOrdenes.select(\"Tasa_de_impuesto\").distinct().show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace una verificación del rango de fechas disponible en los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|min(Fecha_de_pedido)|\n",
      "+--------------------+\n",
      "|          2013-01-01|\n",
      "+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordenes.agg({\"Fecha_de_pedido\": \"min\"}).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se elimina columnas Comenarios, Instrucciones_de_entrega y comentarios_internos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordenes = ordenes.drop(*[\"Comentarios\", \"Instrucciones_de_entrega\",\"comentarios_internos\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se eliminan duplicados totales de ordenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(107707, 93629)\n"
     ]
    }
   ],
   "source": [
    "print((ordenes.count(),ordenes.distinct().count()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordenes = ordenes.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(93629, 93629)\n"
     ]
    }
   ],
   "source": [
    "print((ordenes.count(),ordenes.distinct().count()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se hace verificación de consistencia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#consistencia: revisar genially: definicion de consistencia\n",
    "ids_ordenes = set([x.ID_de_pedido for x in ordenes.select('ID_de_pedido').collect()])\n",
    "ids_detalles = set([x.ID_de_pedido for x in detallesOrdenes.select('ID_de_pedido').collect()])\n",
    "\n",
    "len(ids_ordenes-ids_detalles), len(ids_detalles-ids_ordenes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En el siguiente código para el manejo de fechas, pasamos del formato MM dd,YYYY al formato establecido en la regla de negocio<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20034 73595\n",
      "+------------+-------------+--------------+------------------------------+-------------------------+----------------------+---------------+-------------------------+--------------------------------------+-------------------------------------------+---------------------------+\n",
      "|ID_de_pedido|ID_de_cliente|ID_de_vendedor|Seleccionado_por_ID_de_persona|ID_de_persona_de_contacto|ID_de_pedido_pendiente|Fecha_de_pedido|Fecha_de_entrega_esperada|Numero_de_pedido_de_compra_del_cliente|Pedido_pendiente_de_suministro_insuficiente|Seleccion_completada_cuando|\n",
      "+------------+-------------+--------------+------------------------------+-------------------------+----------------------+---------------+-------------------------+--------------------------------------+-------------------------------------------+---------------------------+\n",
      "|       20972|          132|             6|                             8|                     1263|                  null|    Jan 28,2014|               2014-01-29|                                 14875|                                       true|        2014-01-28 11:00:00|\n",
      "|       22080|          107|            16|                            12|                     1213|                  null|    Feb 17,2014|               2014-02-18|                                 10447|                                       true|        2014-02-17 11:00:00|\n",
      "|       22194|          136|             3|                          null|                     1271|                 22217|    Feb 19,2014|               2014-02-20|                                 12442|                                       true|        2014-02-19 12:00:00|\n",
      "|       22298|          969|             2|                             7|                     3169|                  null|    Feb 20,2014|               2014-02-21|                                 11473|                                       true|        2014-07-10 11:00:00|\n",
      "|       22358|          534|             8|                             6|                     2267|                  null|    Feb 21,2014|               2014-02-24|                                 10078|                                       true|        2014-02-21 11:00:00|\n",
      "+------------+-------------+--------------+------------------------------+-------------------------+----------------------+---------------+-------------------------+--------------------------------------+-------------------------------------------+---------------------------+\n",
      "only showing top 5 rows\n",
      "\n",
      "None\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(20034, 93629)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TRANSFORMACION\n",
    "regex = \"([0-2]\\d{3}-(0[1-9]|1[0-2])-(0[1-9]|[1-2][0-9]|3[0-1]))\"\n",
    "cumplenFormato = ordenes.filter(ordenes[\"Fecha_de_pedido\"].rlike(regex))\n",
    "noCumplenFormato = ordenes.filter(~ordenes[\"Fecha_de_pedido\"].rlike(regex))\n",
    "print(noCumplenFormato.count(), cumplenFormato.count())\n",
    "print(noCumplenFormato.show(5))\n",
    "noCumplenFormato = noCumplenFormato.withColumn('Fecha_de_pedido', f.udf(lambda d: datetime.strptime(d, '%b %d,%Y').strftime('%Y-%m-%d'), t.StringType())(f.col('Fecha_de_pedido')))\n",
    "ordenes = noCumplenFormato.union(cumplenFormato)\n",
    "noCumplenFormato.count(), ordenes.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Descripciones\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----------------+------------+-----------+-----------+---------------+--------+---------------+----------------+---------------------+---------------------------+\n",
      "|Detalle_orden_ID|ID_de_pedido|ID_Producto|Descripcion|ID_Tipo_Paquete|Cantidad|Precio_unitario|Tasa_de_impuesto|Cantidad_seleccionada|Seleccion_completada_cuando|\n",
      "+----------------+------------+-----------+-----------+---------------+--------+---------------+----------------+---------------------+---------------------------+\n",
      "+----------------+------------+-----------+-----------+---------------+--------+---------------+----------------+---------------------+---------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "detallesOrdenes.where(length(col(\"Descripcion\")) <= 10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Imputar valor maximo de cantidad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Cantidad=360)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detallesOrdenes.select('Cantidad').sort(col(\"Cantidad\").desc()).collect()[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "detallesOrdenes = detallesOrdenes.replace( 10000000, 360, 'Cantidad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Row(Cantidad=360)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "detallesOrdenes.select('Cantidad').sort(col(\"Cantidad\").desc()).collect()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detallesOrdenes.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ordenes.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se unen los dos dataframes, se verifica que no haya duplicados y si los hay se eliminan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(294314, 231412)\n",
      "+--------------+-----------+---------------+-------------+--------------+---------------+--------+-----------+---------+----------------+\n",
      "|ID_de_pedido_T|ID_Producto|Fecha_de_pedido|ID_de_cliente|ID_de_vendedor|ID_Tipo_Paquete|Cantidad|Valor_total|Impuestos|ID_de_pedido_DWH|\n",
      "+--------------+-----------+---------------+-------------+--------------+---------------+--------+-----------+---------+----------------+\n",
      "|           148|        203|     2013-01-02|          812|            13|              7|      40|       1280|    19200|               1|\n",
      "|           463|         64|     2013-01-09|          555|             3|              7|       1|         30|      450|               2|\n",
      "|           463|         10|     2013-01-09|          555|             3|              7|       8|        256|     3840|               3|\n",
      "|           463|         16|     2013-01-09|          555|             3|              7|      10|        130|     1950|               4|\n",
      "|           463|         57|     2013-01-09|          555|             3|              7|       3|         39|      585|               5|\n",
      "+--------------+-----------+---------------+-------------+--------------+---------------+--------+-----------+---------+----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ordenes = ordenes.join(detallesOrdenes, how = 'inner', on = 'ID_de_pedido')\n",
    "ordenes = ordenes.withColumn('Valor_total',col('Precio_unitario')*col('Cantidad'))\n",
    "ordenes = ordenes.withColumn('Impuestos',col('Valor_total')*col('Tasa_de_impuesto'))\n",
    "ordenes = ordenes.selectExpr('ID_de_pedido as ID_de_pedido_T','ID_Producto','Fecha_de_pedido','ID_de_cliente','ID_de_vendedor','ID_Tipo_Paquete','Cantidad','Valor_total', 'Impuestos')\n",
    "\n",
    "print((ordenes.count(),ordenes.distinct().count()))\n",
    "\n",
    "ordenes = ordenes.drop_duplicates()\n",
    "ordenes = ordenes.withColumn('ID_de_pedido_DWH', f.monotonically_increasing_id() + 1)\n",
    "ordenes.show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "231.412\n",
      "0\n",
      "50\n",
      "100\n",
      "150\n",
      "200\n"
     ]
    }
   ],
   "source": [
    "# CARGUE\n",
    "inferior = 0\n",
    "superior = 999\n",
    "j=0\n",
    "total = ordenes.count()/1000\n",
    "print(total)\n",
    "collected = ordenes.collect()\n",
    "while j<total:\n",
    "    if j%50==0:\n",
    "        print(j)\n",
    "    j += 1\n",
    "    aux = spark.createDataFrame(collected[inferior:superior],ordenes.columns)\n",
    "    guardar_db(dest_db_connection_string, aux,'Estudiante_43.HechoOrden', db_user, db_psswd)\n",
    "    inferior+=1000\n",
    "    superior+=1000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifique los resultados usando MySQL Workbench"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resultado de consultas\n",
    "Corresponde a las consultas realizadas sobre las tablas, para mostrar el estado final de las tablas pobladas como resultado del proceso de ETL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Tarea ETL\n",
    "Espacio para desarrollar la tarea planteada"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Cierre\n",
    "Completado este tutorial, ya sabe cómo realizar ETL básicos en PySpark.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Información adicional\n",
    "\n",
    "Si quiere conocer más sobre PySpark la guía más detallada es la documentación oficial, la cual puede encontrar acá: https://spark.apache.org/docs/latest/api/python/index.html <br>\n",
    "Para ir directamente a la documentación de PySpark SQL, donde está la información sobre los DataFrames, haga clic en este enlace: https://spark.apache.org/docs/latest/api/python/pyspark.sql.html <br>\n",
    "\n",
    "El Capítulo 2 del libro <i>Learn PySpark : Build Python-based Machine Learning and Deep Learning Models, New York: Apress. 2019</i> de Pramod Singh contiene muchos ejemplos útiles, puede encontrarlo en la biblioteca virtual de la universidad."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Preguntas frecuentes\n",
    "\n",
    "- Si al intentar escribir un <i>dataframe</i> obtiene un error en el formato: \n",
    "    ```\n",
    "    path file:<PATH>/dw/<PATH> already exists.;\n",
    "    ```\n",
    "    Borre la carpeta indicada en el error y vuelva a intentar.\n",
    "\n",
    "- Si al ejecutar su código obtiene el error: \n",
    "    ```\n",
    "    ValueError: Cannot run multiple SparkContexts at once; existing SparkContext(app=tutorial ETL PySpark, master=local) created by __init__ at <ipython-input-4-64455da959dd>:92 \n",
    "\n",
    "    ```\n",
    "    reinicie el kernel del notebook y vuelva a intentar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
